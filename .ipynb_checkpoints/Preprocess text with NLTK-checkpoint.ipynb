{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Cleaning and Tokenization data using nltk, re"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import the regex module\nimport re\n\n# Write a pattern to match sentence endings: sentence_endings\n# sentence_endings = r\"[.?!]\"\n\n# Split string on sentence endings and print the result\n# print(re.split(sentence_endings, string))\n\n# Find all capitalized words in string and print the result\ncapitalized_words = r\"[A-Z]\\w+\"\nprint(re.findall(capitalized_words, string))\n\n# Split string on spaces and print the result\nspaces = r\"\\s+\"\nprint(re.split(spaces, string))\n\n# Find all digits in string and print the result\ndigits = r\"\\d+\"\nprint(re.findall(digits, string))\n\n# Match only words and digits\nmatch_digits_and_words = ('(\\d+|\\w+)')\n\n\nre.search(example, string)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Examples re expressions"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "[A-Za-z]+\tupper and lowercase English alphabet\t'ABCDEFghijk'\n[0-9]\tnumbers from 0 to 9\t9\n[A-Za-z\\-\\.]+\tupper and lowercase English alphabet, - and .\t'My-Website.com'\n(a-z)\ta, - and z\t'a-z'\n(\\s+l,)\tspaces or a comma\t', '",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Tokenize sentences and words"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import nltk, pprint",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import necessary modules\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n\n# Split scene_one into sentences: sentences\nsentences = sent_tokenize(text)\n\n# Use word_tokenize to tokenize the fourth sentence: tokenized_sent\ntokenized_sent = word_tokenize(sentences[3])\n\n# Make a set of unique tokens in the entire scene: unique_tokens\nunique_tokens = set(word_tokenize(text))\n\nprint(unique_tokens)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "#### Examples"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Define hashtags pattern\nhashtag_pattern = r\"#\\w+\"",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open('003-Copy.txt') as text:\n    file = text.read()",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Preprocess with lematization"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import WordNetLemmatizer\nfrom nltk.stem import WordNetLemmatizer\n\n# Retain alphabetic words: alpha_only\nalpha_only = [t for t in lower_tokens if t.isalpha()]\n\n# Remove all stop words: no_stops\nno_stops = [t for t in alpha_only if t not in english_stops]\n\n# Instantiate the WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}